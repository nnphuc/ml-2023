{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55aae51e-b59d-4260-9107-3967c1ea0a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in /opt/conda/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.34.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.1.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.16.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.26.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.3.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.11.3)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.17.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.9.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->sentence_transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence_transformers) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.7.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.26.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.16.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy) (2.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.65.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torchtext in /opt/conda/lib/python3.10/site-packages (0.16.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchtext) (4.65.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchtext) (2.31.0)\n",
      "Requirement already satisfied: torch==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torchtext) (2.1.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchtext) (1.26.0)\n",
      "Requirement already satisfied: torchdata==0.7.0 in /opt/conda/lib/python3.10/site-packages (from torchtext) (0.7.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchtext) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchtext) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchtext) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchtext) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchtext) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchtext) (2023.6.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.10/site-packages (from torchdata==0.7.0->torchtext) (1.26.16)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.1.0->torchtext) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.1.0->torchtext) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.34.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.14.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.17.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install spacy\n",
    "!pip install nltk\n",
    "!pip install torchtext\n",
    "!pip install transformers\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eb00026-ccb0-43c0-ba4f-575095991f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://nlp.stanford.edu/data/glove.6B.zip\n",
    "# !apt install unzip\n",
    "# !unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39d094d8-ec8c-439c-aa4c-fc4b7cd2a6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-08 04:28:20 - Read STSbenchmark train dataset\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer,  LoggingHandler, losses, models, util\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sentence_transformers.readers import InputExample\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "#### /print debug information to stdout\n",
    "\n",
    "\n",
    "\n",
    "#Check if dataset exsist. If not, download and extract  it\n",
    "sts_dataset_path = 'datasets/stsbenchmark.tsv.gz'\n",
    "\n",
    "if not os.path.exists(sts_dataset_path):\n",
    "    util.http_get('https://sbert.net/datasets/stsbenchmark.tsv.gz', sts_dataset_path)\n",
    "\n",
    "\n",
    "\n",
    "# Convert the dataset to a DataLoader ready for training\n",
    "logging.info(\"Read STSbenchmark train dataset\")\n",
    "\n",
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "\n",
    "train_dict = {\n",
    "    \"s1\": [],\n",
    "    \"s2\": [],\n",
    "    \"score\": []\n",
    "}\n",
    "test_dict = {\n",
    "    \"s1\": [],\n",
    "    \"s2\": [],\n",
    "    \"score\": []\n",
    "}\n",
    "dev_dict = {\n",
    "     \"s1\": [],\n",
    "    \"s2\": [],\n",
    "    \"score\": []\n",
    "}\n",
    "with gzip.open(sts_dataset_path, 'rt', encoding='utf8') as fIn:\n",
    "    reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "    for row in reader:\n",
    "        score = float(row['score']) / 5.0  # Normalize score to range 0 ... 1\n",
    "        s1 = row[\"sentence1\"].lower()\n",
    "        s2 = row[\"sentence2\"].lower()\n",
    "\n",
    "        inp_example = InputExample(texts=[row['sentence1'], row['sentence2']], label=score)\n",
    "\n",
    "        if row['split'] == 'dev':\n",
    "            dev_samples.append(inp_example)\n",
    "            dev_dict[\"s1\"].append(s1)\n",
    "            dev_dict[\"s2\"].append(s2)\n",
    "            dev_dict[\"score\"].append(score)\n",
    "        elif row['split'] == 'test':\n",
    "            test_samples.append(inp_example)\n",
    "            test_dict[\"s1\"].append(s1)\n",
    "            test_dict[\"s2\"].append(s2)\n",
    "            test_dict[\"score\"].append(score)\n",
    "        else:\n",
    "            train_samples.append(inp_example)\n",
    "            train_dict[\"s1\"].append(s1)\n",
    "            train_dict[\"s2\"].append(s2)\n",
    "            train_dict[\"score\"].append(score)\n",
    "\n",
    "train_df = pd.DataFrame(train_dict)\n",
    "test_df = pd.DataFrame(test_dict)\n",
    "dev_df = pd.DataFrame(dev_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b91561b-f516-4676-847c-a224ddb78964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['A plane is taking off.', 'An air plane is taking off.'], 1.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples[0].texts, train_samples[0].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1606ff69-3633-4c97-b265-b68efc4a6edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', ',', 'how', 'are', 'you', '?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.data import get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\") ## We'll use tokenizer available from PyTorch\n",
    "\n",
    "tokenizer(\"Hello, How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12785fea-5523-4867-b71a-660a41f7cc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-08 04:28:20 - Loading vectors from .vector_cache/glove.6B.300d.txt.pt\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import GloVe\n",
    "\n",
    "global_vectors = GloVe(name='6B', dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c835e2b4-ca2c-4132-8ee4-ade3a2bc786b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([400000, 300]), 'sandberger')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#global_vectors.get_vecs_by_tokens([\"a\", \"banana\"])\n",
    "global_vectors.vectors.shape, global_vectors.itos[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ed56147-6948-41d0-ad6c-f2bd7477b400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'model' is not defined\n",
      "name 'torch' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import gc\n",
    "    try:\n",
    "        model.cpu()\n",
    "        del model\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f254aa8d-e069-4b51-98a6-414ab95b7920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight.to(x.device)\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "        super().__init__()\n",
    "        self.norm1 = RMSNorm(1)\n",
    "        self.fc = nn.Linear(n_hidden, n_hidden)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.norm1(x)\n",
    "        x2 = self.relu(x1)\n",
    "        x3 = x + x2\n",
    "        return x3\n",
    "        \n",
    "\n",
    "class attbilstm(nn.Module):\n",
    "    def __init__(self, vocab_size, config, vec=None):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = config['hidden_dim']\n",
    "        self.batch_size = config['batch_size']\n",
    "        self.emb_dim = config['emb_dim']\n",
    "        self.gpu = config['gpu']\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, config['emb_dim'])\n",
    "        if vec is not None:\n",
    "            self.embedding.weight.data.copy_(vec) #load pretrained\n",
    "            self.embedding.weight.requires_grad = False #non-trainable\n",
    "        self.encoder = nn.LSTM(config['emb_dim'], config['hidden_dim'], num_layers=config['nlayers'], bidirectional=config['bidir'], dropout=config['dropout'])\n",
    "        self.fc = nn.Linear(config['hidden_dim'] * 2, config['hidden_dim'] * 2)\n",
    "        self.dropout = nn.Dropout(config['dropout'])\n",
    "        self.layers = []\n",
    "        for i in range(config[\"num_layers\"]):\n",
    "            self.layers.append(Block(config['hidden_dim'] * 2))\n",
    "        # self.hidden = nn.Parameters(self.batch_size, self.hidden_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def attnetwork(self, encoder_out, final_hidden):\n",
    "        hidden = final_hidden.squeeze(0)\n",
    "        #M = torch.tanh(encoder_out)\n",
    "        attn_weights = torch.bmm(encoder_out, hidden.unsqueeze(2)).squeeze(2)\n",
    "        soft_attn_weights = F.softmax(attn_weights, 1)\n",
    "        new_hidden = torch.bmm(encoder_out.transpose(1,2), soft_attn_weights.unsqueeze(2)).squeeze(2)\n",
    "        # print (wt.shape, new_hidden.shape)\n",
    "        # new_hidden = torch.tanh(new_hidden)\n",
    "        # print ('UP:', new_hidden.shape)\n",
    "        # print(\"soft_attn_weights\", soft_attn_weights.shape)\n",
    "        \n",
    "        return new_hidden, soft_attn_weights\n",
    "    \n",
    "    def forward(self, sequence):\n",
    "        #print(sequence.shape)\n",
    "        emb_input = self.embedding(sequence)    \n",
    "        inputx = self.dropout(emb_input)\n",
    "        output, (hn, cn) = self.encoder(inputx)\n",
    "        # print(\"shape output, hn, cn\", output.shape, hn.shape, cn.shape)\n",
    "        fbout = output[:, :, :self.hidden_dim]+ output[:, :, self.hidden_dim:] #sum bidir outputs F+B\n",
    "        fbout = fbout.permute(1,0,2)\n",
    "        fbhn = (hn[-2,:,:]+hn[-1,:,:]).unsqueeze(0)\n",
    "        # print(fbout.shape, fbhn.shape)\n",
    "        attn_out, attn_weight = self.attnetwork(fbout, fbhn)\n",
    "        # print(\"att shape\", attn_out.shape, attn_weight.shape)\n",
    "        #attn1_out = self.attnetwork1(output, hn)\n",
    "        # logits = self.fc(attn_out)\n",
    "        # print(fbout.shape, output.shape, attn_weight.permute(1,0).unsqueeze(-1).shape)\n",
    "        out = output * attn_weight.permute(1,0).unsqueeze(-1)\n",
    "        out = torch.mean(out, dim=(1))\n",
    "        for l in self.layers:\n",
    "            out = l(out)\n",
    "        #print(\"out, attn\", out.shape, attn_weight.shape)\n",
    "        # out = self.sigmoid(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b28c742f-7212-4f00-a0c5-3bdde6d13021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-7.2892e-03,  2.7604e+00,  7.0965e-01,  ..., -1.6619e-02,\n",
       "           2.5715e+00, -1.0113e-02],\n",
       "         [-1.1048e-02,  4.1293e+00,  1.2515e+00,  ..., -8.3236e-03,\n",
       "           3.8774e+00, -4.1962e-03],\n",
       "         [-1.2167e-02,  3.9126e+00, -3.2774e-03,  ..., -3.1512e-03,\n",
       "           5.0554e-01,  1.8145e+00]], grad_fn=<AddBackward0>),\n",
       " torch.Size([3, 512]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    \"hidden_dim\": 256,\n",
    "    \"batch_size\": 4,\n",
    "    \"emb_dim\": 300,\n",
    "    \"nlayers\": 2,\n",
    "    \"dropout\": 0.5,\n",
    "    \"bidir\": True,\n",
    "    \"gpu\": True,\n",
    "    \"out_dim\": 256,\n",
    "    \"num_layers\": 8\n",
    "}\n",
    "global_vectors.vectors.shape\n",
    "vectors = torch.vstack([global_vectors.vectors, torch.zeros((1, 300))])\n",
    "vocab_size = vectors.shape[0]\n",
    "model = attbilstm(vocab_size=vocab_size, config=config, vec=vectors)\n",
    "\n",
    "output = model.forward(torch.from_numpy(np.array([[1, 0, 0, 0], [2,3,0, 0], [4,5,6, 0]])))\n",
    "output, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba5a495d-8eec-40a5-8db4-ab5d1a695684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.to(\"cuda\")\n",
    "# torch.save(model.state_dict(), \"test.pt\")\n",
    "# model.load_state_dict(torch.load(\"test.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c3c802e-f6d4-4824-8247-c41bf4f30897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([400001, 300]), torch.float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_vectors.vectors.shape\n",
    "torch.vstack([global_vectors.vectors, torch.zeros((1, 300))]).shape, global_vectors.vectors.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f148546d-19b4-4b7c-81d8-9b5a2027dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global_vectors.unk_init = nn.init.xavier_uniform_\n",
    "\n",
    "def process_df(train_df, mx = 64):\n",
    "    t = []\n",
    "    for line in train_df[\"s1\"]:\n",
    "        parts = tokenizer(line)\n",
    "        l = []\n",
    "        for k in parts:\n",
    "            if k in global_vectors.stoi:\n",
    "                l.append(global_vectors.stoi[k])\n",
    "            # else:\n",
    "                # l.append(global_vectors.vectors.shape[0]-1)\n",
    "        l.extend([vectors.shape[0]-1] * (mx - len(l)))\n",
    "        t.append(np.array(l))\n",
    "        \n",
    "    \n",
    "    train_df[\"i1\"] = t\n",
    "    \n",
    "    t = []\n",
    "    for line in train_df[\"s2\"]:\n",
    "        parts = tokenizer(line)\n",
    "        l = []\n",
    "        for k in parts:\n",
    "            if k in global_vectors.stoi:\n",
    "                l.append(global_vectors.stoi[k])\n",
    "            # else:\n",
    "            #     l.append(global_vectors.vectors.shape[0]-1)\n",
    "        l.extend([vectors.shape[0]-1] * (mx - len(l)))\n",
    "        t.append(np.array(l))\n",
    "    train_df[\"i2\"] = t\n",
    "\n",
    "process_df(train_df)\n",
    "process_df(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc71297c-bd82-4469-99c1-eefa950c37d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>score</th>\n",
       "      <th>i1</th>\n",
       "      <th>i2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a plane is taking off.</td>\n",
       "      <td>an air plane is taking off.</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[7, 1313, 14, 582, 138, 2, 400000, 400000, 400...</td>\n",
       "      <td>[29, 325, 1313, 14, 582, 138, 2, 400000, 40000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a man is playing a large flute.</td>\n",
       "      <td>a man is playing a flute.</td>\n",
       "      <td>0.76</td>\n",
       "      <td>[7, 300, 14, 697, 7, 426, 16677, 2, 400000, 40...</td>\n",
       "      <td>[7, 300, 14, 697, 7, 16677, 2, 400000, 400000,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a man is spreading shreded cheese on a pizza.</td>\n",
       "      <td>a man is spreading shredded cheese on an uncoo...</td>\n",
       "      <td>0.76</td>\n",
       "      <td>[7, 300, 14, 6002, 5795, 13, 7, 9388, 2, 40000...</td>\n",
       "      <td>[7, 300, 14, 6002, 20256, 5795, 13, 29, 53867,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>three men are playing chess.</td>\n",
       "      <td>two men are playing chess.</td>\n",
       "      <td>0.52</td>\n",
       "      <td>[87, 301, 32, 697, 7162, 2, 400000, 400000, 40...</td>\n",
       "      <td>[55, 301, 32, 697, 7162, 2, 400000, 400000, 40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a man is playing the cello.</td>\n",
       "      <td>a man seated is playing the cello.</td>\n",
       "      <td>0.85</td>\n",
       "      <td>[7, 300, 14, 697, 0, 19641, 2, 400000, 400000,...</td>\n",
       "      <td>[7, 300, 9928, 14, 697, 0, 19641, 2, 400000, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5744</th>\n",
       "      <td>severe gales as storm clodagh hits britain</td>\n",
       "      <td>merkel pledges nato solidarity with latvia</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[2546, 43694, 19, 1836, 213914, 2042, 695, 400...</td>\n",
       "      <td>[6648, 7700, 945, 6132, 17, 7211, 400000, 4000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5745</th>\n",
       "      <td>dozens of egyptians hostages taken by libyan t...</td>\n",
       "      <td>egyptian boat crash death toll rises as more b...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[2209, 3, 13007, 4005, 492, 21, 7176, 2712, 19...</td>\n",
       "      <td>[2434, 2377, 2005, 336, 2493, 4890, 19, 56, 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5746</th>\n",
       "      <td>president heading to bahrain</td>\n",
       "      <td>president xi: china to continue help to fight ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[90, 3339, 4, 6700, 400000, 400000, 400000, 40...</td>\n",
       "      <td>[90, 9163, 132, 4, 660, 275, 4, 838, 19127, 40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5747</th>\n",
       "      <td>china, india vow to further bilateral ties</td>\n",
       "      <td>china scrambles to reassure jittery stock traders</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[132, 1, 474, 12887, 4, 489, 2902, 1445, 40000...</td>\n",
       "      <td>[132, 45583, 4, 12182, 21350, 452, 3182, 40000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5748</th>\n",
       "      <td>putin spokesman: doping charges appear unfounded</td>\n",
       "      <td>the latest on severe weather: 1 dead in texas ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[2727, 391, 5663, 840, 1650, 17271, 400000, 40...</td>\n",
       "      <td>[0, 993, 13, 2546, 1620, 176, 767, 6, 745, 49,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5749 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     s1  \\\n",
       "0                                a plane is taking off.   \n",
       "1                       a man is playing a large flute.   \n",
       "2         a man is spreading shreded cheese on a pizza.   \n",
       "3                          three men are playing chess.   \n",
       "4                           a man is playing the cello.   \n",
       "...                                                 ...   \n",
       "5744         severe gales as storm clodagh hits britain   \n",
       "5745  dozens of egyptians hostages taken by libyan t...   \n",
       "5746                       president heading to bahrain   \n",
       "5747         china, india vow to further bilateral ties   \n",
       "5748   putin spokesman: doping charges appear unfounded   \n",
       "\n",
       "                                                     s2  score  \\\n",
       "0                           an air plane is taking off.   1.00   \n",
       "1                             a man is playing a flute.   0.76   \n",
       "2     a man is spreading shredded cheese on an uncoo...   0.76   \n",
       "3                            two men are playing chess.   0.52   \n",
       "4                    a man seated is playing the cello.   0.85   \n",
       "...                                                 ...    ...   \n",
       "5744         merkel pledges nato solidarity with latvia   0.00   \n",
       "5745  egyptian boat crash death toll rises as more b...   0.00   \n",
       "5746  president xi: china to continue help to fight ...   0.00   \n",
       "5747  china scrambles to reassure jittery stock traders   0.00   \n",
       "5748  the latest on severe weather: 1 dead in texas ...   0.00   \n",
       "\n",
       "                                                     i1  \\\n",
       "0     [7, 1313, 14, 582, 138, 2, 400000, 400000, 400...   \n",
       "1     [7, 300, 14, 697, 7, 426, 16677, 2, 400000, 40...   \n",
       "2     [7, 300, 14, 6002, 5795, 13, 7, 9388, 2, 40000...   \n",
       "3     [87, 301, 32, 697, 7162, 2, 400000, 400000, 40...   \n",
       "4     [7, 300, 14, 697, 0, 19641, 2, 400000, 400000,...   \n",
       "...                                                 ...   \n",
       "5744  [2546, 43694, 19, 1836, 213914, 2042, 695, 400...   \n",
       "5745  [2209, 3, 13007, 4005, 492, 21, 7176, 2712, 19...   \n",
       "5746  [90, 3339, 4, 6700, 400000, 400000, 400000, 40...   \n",
       "5747  [132, 1, 474, 12887, 4, 489, 2902, 1445, 40000...   \n",
       "5748  [2727, 391, 5663, 840, 1650, 17271, 400000, 40...   \n",
       "\n",
       "                                                     i2  \n",
       "0     [29, 325, 1313, 14, 582, 138, 2, 400000, 40000...  \n",
       "1     [7, 300, 14, 697, 7, 16677, 2, 400000, 400000,...  \n",
       "2     [7, 300, 14, 6002, 20256, 5795, 13, 29, 53867,...  \n",
       "3     [55, 301, 32, 697, 7162, 2, 400000, 400000, 40...  \n",
       "4     [7, 300, 9928, 14, 697, 0, 19641, 2, 400000, 4...  \n",
       "...                                                 ...  \n",
       "5744  [6648, 7700, 945, 6132, 17, 7211, 400000, 4000...  \n",
       "5745  [2434, 2377, 2005, 336, 2493, 4890, 19, 56, 17...  \n",
       "5746  [90, 9163, 132, 4, 660, 275, 4, 838, 19127, 40...  \n",
       "5747  [132, 45583, 4, 12182, 21350, 452, 3182, 40000...  \n",
       "5748  [0, 993, 13, 2546, 1620, 176, 767, 6, 745, 49,...  \n",
       "\n",
       "[5749 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0552ac4b-4d2a-40b2-a537-7804804a2fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import IterableDataset\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "829dcd5d-aa25-49c8-801b-e0772b7c8591",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t = self.df.iloc[idx]\n",
    "        return t[3],t[4], t[2]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc3d1f9-2615-414c-9809-c241bd79bd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]/tmp/ipykernel_2096/620000983.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return t[3],t[4], t[2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- 1\n",
      "avg_train_loss = 0.13091778094983764\n",
      "test model  train\n",
      "avg_train_loss = 0.1039533252083504, p= SignificanceResult(statistic=0.0770661304859091, pvalue=4.893546241267359e-09)\n",
      "test model  test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/10000 [00:08<22:50:18,  8.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_test_loss = 0.14002217002289824, p= SignificanceResult(statistic=0.09649716068432411, pvalue=0.0003325362758987969)\n",
      "---------- 2\n",
      "avg_train_loss = 0.10516761852842238\n",
      "test model  train\n",
      "avg_train_loss = 0.09978624621332445, p= SignificanceResult(statistic=0.06580695774364458, pvalue=5.915540846895201e-07)\n",
      "test model  test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/10000 [00:15<21:56:59,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_test_loss = 0.13030988721273287, p= SignificanceResult(statistic=0.055774976816270784, pvalue=0.03836519716866538)\n",
      "---------- 3\n",
      "avg_train_loss = 0.10109734749938878\n",
      "test model  train\n",
      "avg_train_loss = 0.096375494507379, p= SignificanceResult(statistic=0.09131676973609479, pvalue=4.0100773478644114e-12)\n",
      "test model  test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/10000 [00:23<22:09:48,  7.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_test_loss = 0.12677762630302936, p= SignificanceResult(statistic=0.11737694733725153, pvalue=1.2428030766860527e-05)\n",
      "---------- 4\n",
      "avg_train_loss = 0.09850424243551162\n",
      "test model  train\n",
      "avg_train_loss = 0.0976708659588712, p= SignificanceResult(statistic=0.0717751462173519, pvalue=5.094208294205859e-08)\n",
      "test model  test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/10000 [00:31<22:04:55,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_test_loss = 0.1254943662777841, p= SignificanceResult(statistic=0.11661966429506937, pvalue=1.4147949057458374e-05)\n",
      "---------- 5\n",
      "avg_train_loss = 0.09439895167015493\n",
      "test model  train\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import tqdm\n",
    "from scipy import stats\n",
    "ds = CustomDataset(train_df)\n",
    "dl = DataLoader(ds, batch_size=16, shuffle=True) \n",
    "\n",
    "test_ds = CustomDataset(test_df)\n",
    "test_dl = DataLoader(test_ds, batch_size=4)\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from typing import Iterable, Dict\n",
    "\n",
    "\n",
    "\n",
    "class CosineSimilarityLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, loss_fct = nn.MSELoss(), cos_score_transformation=nn.Identity()):\n",
    "        super(CosineSimilarityLoss, self).__init__()\n",
    "        self.loss_fct = loss_fct\n",
    "        self.cos_score_transformation = cos_score_transformation\n",
    "\n",
    "\n",
    "    def forward(self, embeddings, labels: Tensor):\n",
    "        emb_1 = embeddings[0]\n",
    "        emb_2 = embeddings[1]\n",
    "        output = self.cos_score_transformation(nn.functional.cosine_similarity(emb_1, emb_2))\n",
    "        return self.loss_fct(output, labels.view(-1))\n",
    "\n",
    "def predict(s1, s2):\n",
    "    emb_1 = model(s1)\n",
    "    emb_2 = model(s2)\n",
    "    out = nn.functional.cosine_similarity(emb_1, emb_2)\n",
    "    return out\n",
    "\n",
    "def test(model, dl, crition, name=\"test\"):\n",
    "    print(\"test model \", name)\n",
    "    s1 = []\n",
    "    s2 = []\n",
    "    avg_loss = 0\n",
    "    for i,b in enumerate(dl):\n",
    "        i1, i2, s = b\n",
    "        emb_1 = model(i1.to(device))\n",
    "        emb_2 = model(i2.to(device))\n",
    "        score = nn.functional.cosine_similarity(emb_1, emb_2)\n",
    "        s1.append(score.cpu().detach().numpy())\n",
    "        s2.append(s.cpu().detach().numpy())\n",
    "        #print(score, s)\n",
    "        avg_loss += crition([emb_1,emb_2], s.to(device))\n",
    "    x = np.hstack(s1)\n",
    "    y = np.hstack(s2)\n",
    "    p = stats.spearmanr(x,y)\n",
    "    print(f\"avg_{name}_loss = {avg_loss/len(dl)}, p= {p}\")\n",
    "\n",
    "device = \"cuda\"\n",
    "model.to(device)\n",
    "crition = CosineSimilarityLoss().to(device)\n",
    "optimizer = torch.optim.Adam(lr=0.0001, params = model.parameters())\n",
    "\n",
    "num_epoch = 10000\n",
    "save_every = 100\n",
    "#test(model, test_dl)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in tqdm.tqdm(range(num_epoch)):\n",
    "    print(\"-\" * 10, epoch + 1)\n",
    "    avg_loss = 0\n",
    "    model.train()\n",
    "    for i, b in enumerate(dl):\n",
    "        i1, i2, s = b\n",
    "        #print(i1.shape, i2.shape, s.shape)\n",
    "        s = s.to(torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        o1 = model(i1.to(device))\n",
    "        o2 = model(i2.to(device))\n",
    "        #print(\"o1.shape, o2.shape\", o1.shape, o2.shape)\n",
    "        loss = crition([o1,o2], s.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss += loss.item()\n",
    "        # if (i + 1) % 50 == 0:\n",
    "            # print(f\"loss = {loss.item()}, epoch={epoch}\")\n",
    "    \n",
    "    print(f\"avg_train_loss = {avg_loss/len(dl)}\")\n",
    "    test(model, dl, crition, \"train\")\n",
    "    test(model, test_dl, crition, \"test\")\n",
    "    if  (epoch + 1 ) % save_every == 0:\n",
    "        try:\n",
    "            torch.save(model.state_dict(), f\"models/model-{epoch+1}.pt\")\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6052e4-9d38-4617-8335-a82af99601f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.hstack([np.array([1,2]), np.array([3])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
